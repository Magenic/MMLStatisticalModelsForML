{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import random\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Activation, Dropout, Flatten, Dense, Flatten, RepeatVector, TimeDistributed, InputLayer, Lambda\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.initializers import RandomUniform, Initializer, Constant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InitCentersRandom(Initializer):\n",
    "\n",
    "    def __init__(self, X):\n",
    "        self.X = X\n",
    "\n",
    "    def __call__(self, shape, dtype=None):\n",
    "        assert shape[1] == self.X.shape[1]\n",
    "        idx = np.random.randint(self.X.shape[0], size=shape[0])\n",
    "        return self.X[idx, :]\n",
    "\n",
    "class RBFLayer(keras.layers.Layer):\n",
    "\n",
    "    def __init__(self, output_dim, initializer=None, betas=1.0, **kwargs):\n",
    "        self.output_dim = output_dim\n",
    "        self.init_betas = betas\n",
    "        if not initializer:\n",
    "            self.initializer = RandomUniform(0.0, 1.0)\n",
    "        else:\n",
    "            self.initializer = initializer\n",
    "        super(RBFLayer, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "\n",
    "        self.centers = self.add_weight(name='centers',\n",
    "                                       shape=(self.output_dim, input_shape[1]),\n",
    "                                       initializer=self.initializer,\n",
    "                                       trainable=True)\n",
    "        self.betas = self.add_weight(name='betas',\n",
    "                                     shape=(self.output_dim,),\n",
    "                                     initializer=Constant(\n",
    "                                         value=self.init_betas),\n",
    "                                     # initializer='ones',\n",
    "                                     trainable=True)\n",
    "\n",
    "        super(RBFLayer, self).build(input_shape)\n",
    "\n",
    "    def call(self, x):\n",
    "\n",
    "        C = K.expand_dims(self.centers)\n",
    "        H = K.transpose(C-K.transpose(x))\n",
    "        return K.exp(-self.betas * K.sum(H**2, axis=1))\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return (input_shape[0], self.output_dim)\n",
    "\n",
    "    def get_config(self):\n",
    "        # have to define get_config to be able to use model_from_json\n",
    "        config = {\n",
    "            'output_dim': self.output_dim\n",
    "        }\n",
    "        base_config = super(RBFLayer, self).get_config()\n",
    "        return dict(list(base_config.items()) + list(config.items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = 'collateral/train_mod.csv'\n",
    "kval = 4\n",
    "itertot = 40\n",
    "itergd = 300\n",
    "    \n",
    "dataread = np.genfromtxt(data, delimiter=',')[1:,1:]\n",
    "alldata = []\n",
    "for i in range(len(dataread)):\n",
    "    if np.isnan(dataread[i,-2]):\n",
    "        continue\n",
    "    alldata.append(dataread[i])\n",
    "\n",
    "\n",
    "alldata = np.asarray(alldata)\n",
    "\n",
    "#dividing data\n",
    "trainparam = alldata[:600,1:]\n",
    "trainlabel = alldata[:600,0]\n",
    "testparam = alldata[600:,1:]\n",
    "testlabel = alldata[600:,0]\n",
    "\n",
    "std = np.zeros((len(trainparam[0]))).astype('float32')\n",
    "rata = np.zeros((len(trainparam[0]))).astype('float32')\n",
    "trainparamnorm = np.zeros(np.shape(trainparam))\n",
    "testparamnorm = np.zeros(np.shape(testparam))\n",
    "for i in range(len(trainparam[0])):\n",
    "    std[i] = np.std(trainparam[:,i])\n",
    "    rata[i] = np.mean(trainparam[:,i])\n",
    "    trainparamnorm[:,i] = (trainparam[:,i] - rata[i]) / std[i]\n",
    "    testparamnorm[:,i] = (testparam[:,i] - rata[i]) / std[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calczscore(x):    \n",
    "    output = x\n",
    "    \n",
    "    if not x.shape[0] is None:\n",
    "        o = []\n",
    "        for i in range(x.shape[0]):\n",
    "            o.append([])\n",
    "            for n in range(x[i].shape[0]):\n",
    "                o[i].append((x[i][n] - rata[n]) / std[n])\n",
    "        output = tf.reshape(o, shape=x.shape)\n",
    "    return output\n",
    "\n",
    "def generatemodel(numparam):\n",
    "    model = Sequential()\n",
    "    model.add(Flatten(input_shape=((numparam, 1))))\n",
    "    model.add(RBFLayer(kval,\n",
    "                      initializer=InitCentersRandom(calczscore(trainparam).numpy()),\n",
    "                      betas=2.0))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.6999 - accuracy: 0.4267\n",
      "Epoch 2/300\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 0.6951 - accuracy: 0.5167\n",
      "Epoch 3/300\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.6909 - accuracy: 0.5950\n",
      "Epoch 4/300\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.6869 - accuracy: 0.6033\n",
      "Epoch 5/300\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.6831 - accuracy: 0.6067\n",
      "Epoch 6/300\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 0.6793 - accuracy: 0.6117\n",
      "Epoch 7/300\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.6756 - accuracy: 0.6117\n",
      "Epoch 8/300\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.6720 - accuracy: 0.6183\n",
      "Epoch 9/300\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 0.6684 - accuracy: 0.6217\n",
      "Epoch 10/300\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.6651 - accuracy: 0.6250\n",
      "Epoch 11/300\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.6618 - accuracy: 0.6250\n",
      "Epoch 12/300\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 0.6587 - accuracy: 0.6300\n",
      "Epoch 13/300\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.6556 - accuracy: 0.6317\n",
      "Epoch 14/300\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.6527 - accuracy: 0.6317\n",
      "Epoch 15/300\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6498 - accuracy: 0.6317\n",
      "Epoch 16/300\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6470 - accuracy: 0.6350\n",
      "Epoch 17/300\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6442 - accuracy: 0.6367\n",
      "Epoch 18/300\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.6414 - accuracy: 0.6383\n",
      "Epoch 19/300\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 0.6386 - accuracy: 0.6433\n",
      "Epoch 20/300\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 0.6357 - accuracy: 0.6467\n",
      "Epoch 21/300\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.6331 - accuracy: 0.6467\n",
      "Epoch 22/300\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 0.6302 - accuracy: 0.6467\n",
      "Epoch 23/300\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 0.6273 - accuracy: 0.6483\n",
      "Epoch 24/300\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.6244 - accuracy: 0.6533\n",
      "Epoch 25/300\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.6214 - accuracy: 0.6567\n",
      "Epoch 26/300\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6185 - accuracy: 0.6583\n",
      "Epoch 27/300\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 0.6154 - accuracy: 0.6567\n",
      "Epoch 28/300\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.6122 - accuracy: 0.6567\n",
      "Epoch 29/300\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 0.6089 - accuracy: 0.6567\n",
      "Epoch 30/300\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.6056 - accuracy: 0.6550\n",
      "Epoch 31/300\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.6024 - accuracy: 0.6583\n",
      "Epoch 32/300\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.5986 - accuracy: 0.6600\n",
      "Epoch 33/300\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.5950 - accuracy: 0.6617\n",
      "Epoch 34/300\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 0.5914 - accuracy: 0.6617\n",
      "Epoch 35/300\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.5874 - accuracy: 0.6700\n",
      "Epoch 36/300\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.5836 - accuracy: 0.6717\n",
      "Epoch 37/300\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 0.5797 - accuracy: 0.6800\n",
      "Epoch 38/300\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 0.5756 - accuracy: 0.6817\n",
      "Epoch 39/300\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 0.5716 - accuracy: 0.6933\n",
      "Epoch 40/300\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 0.5676 - accuracy: 0.7050\n",
      "Epoch 41/300\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.5637 - accuracy: 0.7150\n",
      "Epoch 42/300\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 0.5599 - accuracy: 0.7200\n",
      "Epoch 43/300\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.5562 - accuracy: 0.7283\n",
      "Epoch 44/300\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.5528 - accuracy: 0.7383\n",
      "Epoch 45/300\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.5494 - accuracy: 0.7333\n",
      "Epoch 46/300\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 0.5463 - accuracy: 0.7500\n",
      "Epoch 47/300\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.5435 - accuracy: 0.7483\n",
      "Epoch 48/300\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.5407 - accuracy: 0.7533\n",
      "Epoch 49/300\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 0.5379 - accuracy: 0.7633\n",
      "Epoch 50/300\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.5354 - accuracy: 0.7633\n",
      "Epoch 51/300\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 0.5334 - accuracy: 0.7650\n",
      "Epoch 52/300\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 0.5309 - accuracy: 0.7600\n",
      "Epoch 53/300\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.5286 - accuracy: 0.7683\n",
      "Epoch 54/300\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 0.5264 - accuracy: 0.7700\n",
      "Epoch 55/300\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.5244 - accuracy: 0.7700\n",
      "Epoch 56/300\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.5225 - accuracy: 0.7667\n",
      "Epoch 57/300\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 0.5205 - accuracy: 0.7667\n",
      "Epoch 58/300\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.5187 - accuracy: 0.7667\n",
      "Epoch 59/300\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 0.5172 - accuracy: 0.7700\n",
      "Epoch 60/300\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 0.5155 - accuracy: 0.7667\n",
      "Epoch 61/300\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.5136 - accuracy: 0.7683\n",
      "Epoch 62/300\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.5121 - accuracy: 0.7683\n",
      "Epoch 63/300\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.5105 - accuracy: 0.7700\n",
      "Epoch 64/300\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.5090 - accuracy: 0.7717\n",
      "Epoch 65/300\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.5076 - accuracy: 0.7700\n",
      "Epoch 66/300\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 0.5064 - accuracy: 0.7700\n",
      "Epoch 67/300\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.5052 - accuracy: 0.7683\n",
      "Epoch 68/300\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.5035 - accuracy: 0.7717\n",
      "Epoch 69/300\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 0.5024 - accuracy: 0.7717\n",
      "Epoch 70/300\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.5011 - accuracy: 0.7717\n",
      "Epoch 71/300\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 0.4998 - accuracy: 0.7750\n",
      "Epoch 72/300\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.4986 - accuracy: 0.7750\n",
      "Epoch 73/300\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.4976 - accuracy: 0.7750\n",
      "Epoch 74/300\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 0.4963 - accuracy: 0.7767\n",
      "Epoch 75/300\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.4952 - accuracy: 0.7767\n",
      "Epoch 76/300\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.4941 - accuracy: 0.7783\n",
      "Epoch 77/300\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.4932 - accuracy: 0.7800\n",
      "Epoch 78/300\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.4924 - accuracy: 0.7800\n",
      "Epoch 79/300\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 0.4912 - accuracy: 0.7783\n",
      "Epoch 80/300\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.4903 - accuracy: 0.7767\n",
      "Epoch 81/300\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.4892 - accuracy: 0.7767\n",
      "Epoch 82/300\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.4883 - accuracy: 0.7767\n",
      "Epoch 83/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30/30 [==============================] - 0s 4ms/step - loss: 0.4875 - accuracy: 0.7800\n",
      "Epoch 84/300\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.4866 - accuracy: 0.7750\n",
      "Epoch 85/300\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.4857 - accuracy: 0.7750\n",
      "Epoch 86/300\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.4849 - accuracy: 0.7800\n",
      "Epoch 87/300\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.4840 - accuracy: 0.7767\n",
      "Epoch 88/300\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.4837 - accuracy: 0.7667\n",
      "Epoch 89/300\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.4825 - accuracy: 0.7750\n",
      "Epoch 90/300\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.4817 - accuracy: 0.7683\n",
      "Epoch 91/300\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.4809 - accuracy: 0.7733\n",
      "Epoch 92/300\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.4801 - accuracy: 0.7750\n",
      "Epoch 93/300\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.4797 - accuracy: 0.7767\n",
      "Epoch 94/300\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.4789 - accuracy: 0.7700\n",
      "Epoch 95/300\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.4782 - accuracy: 0.7767\n",
      "Epoch 96/300\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 0.4775 - accuracy: 0.7767\n",
      "Epoch 97/300\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 0.4768 - accuracy: 0.7750\n",
      "Epoch 98/300\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.4765 - accuracy: 0.7750\n",
      "Epoch 99/300\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.4755 - accuracy: 0.7817\n",
      "Epoch 100/300\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.4749 - accuracy: 0.7817\n",
      "Epoch 101/300\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 0.4748 - accuracy: 0.7733\n",
      "Epoch 102/300\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.4738 - accuracy: 0.7767\n",
      "Epoch 103/300\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.4733 - accuracy: 0.7767\n",
      "Epoch 104/300\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.4724 - accuracy: 0.7767\n",
      "Epoch 105/300\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.4719 - accuracy: 0.7750\n",
      "Epoch 106/300\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 0.4715 - accuracy: 0.7767\n",
      "Epoch 107/300\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.4709 - accuracy: 0.7800\n",
      "Epoch 108/300\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 0.4703 - accuracy: 0.7800\n",
      "Epoch 109/300\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 0.4697 - accuracy: 0.7783\n",
      "Epoch 110/300\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.4693 - accuracy: 0.7800\n",
      "Epoch 111/300\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 0.4688 - accuracy: 0.7783\n",
      "Epoch 112/300\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 0.4682 - accuracy: 0.7733\n",
      "Epoch 113/300\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.4677 - accuracy: 0.7767\n",
      "Epoch 114/300\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 0.4673 - accuracy: 0.7783\n",
      "Epoch 115/300\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.4671 - accuracy: 0.7767\n",
      "Epoch 116/300\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 0.4665 - accuracy: 0.7767\n",
      "Epoch 117/300\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.4662 - accuracy: 0.7733\n",
      "Epoch 118/300\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.4656 - accuracy: 0.7783\n",
      "Epoch 119/300\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.4651 - accuracy: 0.7750\n",
      "Epoch 120/300\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.4647 - accuracy: 0.7750\n",
      "Epoch 121/300\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 0.4642 - accuracy: 0.7767\n",
      "Epoch 122/300\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.4639 - accuracy: 0.7767\n",
      "Epoch 123/300\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 0.4636 - accuracy: 0.7767\n",
      "Epoch 124/300\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 0.4631 - accuracy: 0.7783\n",
      "Epoch 125/300\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.4628 - accuracy: 0.7750\n",
      "Epoch 126/300\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 0.4623 - accuracy: 0.7767\n",
      "Epoch 127/300\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.4621 - accuracy: 0.7783\n",
      "Epoch 128/300\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.4617 - accuracy: 0.7750\n",
      "Epoch 129/300\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 0.4614 - accuracy: 0.7750\n",
      "Epoch 130/300\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.4610 - accuracy: 0.7750\n",
      "Epoch 131/300\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 0.4609 - accuracy: 0.7750\n",
      "Epoch 132/300\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 0.4605 - accuracy: 0.7767\n",
      "Epoch 133/300\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.4603 - accuracy: 0.7750\n",
      "Epoch 134/300\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 0.4600 - accuracy: 0.7833\n",
      "Epoch 135/300\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.4598 - accuracy: 0.7750\n",
      "Epoch 136/300\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.4592 - accuracy: 0.7800\n",
      "Epoch 137/300\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.4592 - accuracy: 0.7817\n",
      "Epoch 138/300\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 0.4587 - accuracy: 0.7767\n",
      "Epoch 139/300\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.4583 - accuracy: 0.7783\n",
      "Epoch 140/300\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.4586 - accuracy: 0.7800\n",
      "Epoch 141/300\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 0.4581 - accuracy: 0.7717\n",
      "Epoch 142/300\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.4579 - accuracy: 0.7717\n",
      "Epoch 143/300\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.4574 - accuracy: 0.7767\n",
      "Epoch 144/300\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 0.4574 - accuracy: 0.7750\n",
      "Epoch 145/300\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.4570 - accuracy: 0.7750\n",
      "Epoch 146/300\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 0.4568 - accuracy: 0.7800\n",
      "Epoch 147/300\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 0.4565 - accuracy: 0.7850\n",
      "Epoch 148/300\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.4563 - accuracy: 0.7817\n",
      "Epoch 149/300\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.4562 - accuracy: 0.7800\n",
      "Epoch 150/300\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 0.4564 - accuracy: 0.7833\n",
      "Epoch 151/300\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.4561 - accuracy: 0.7750\n",
      "Epoch 152/300\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 0.4559 - accuracy: 0.7750\n",
      "Epoch 153/300\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.4554 - accuracy: 0.7833\n",
      "Epoch 154/300\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.4557 - accuracy: 0.7817\n",
      "Epoch 155/300\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.4549 - accuracy: 0.7817\n",
      "Epoch 156/300\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 0.4549 - accuracy: 0.7817\n",
      "Epoch 157/300\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 0.4546 - accuracy: 0.7783\n",
      "Epoch 158/300\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.4545 - accuracy: 0.7817\n",
      "Epoch 159/300\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 0.4548 - accuracy: 0.7783\n",
      "Epoch 160/300\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 0.4543 - accuracy: 0.7883\n",
      "Epoch 161/300\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.4542 - accuracy: 0.7817\n",
      "Epoch 162/300\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 0.4538 - accuracy: 0.7833\n",
      "Epoch 163/300\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.4542 - accuracy: 0.7667\n",
      "Epoch 164/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30/30 [==============================] - 0s 4ms/step - loss: 0.4533 - accuracy: 0.7817\n",
      "Epoch 165/300\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 0.4540 - accuracy: 0.7817\n",
      "Epoch 166/300\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.4531 - accuracy: 0.7850\n",
      "Epoch 167/300\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.4533 - accuracy: 0.7850\n",
      "Epoch 168/300\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.4530 - accuracy: 0.7883\n",
      "Epoch 169/300\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.4530 - accuracy: 0.7833\n",
      "Epoch 170/300\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 0.4530 - accuracy: 0.7817\n",
      "Epoch 171/300\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.4527 - accuracy: 0.7767\n",
      "Epoch 172/300\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.4525 - accuracy: 0.7817\n",
      "Epoch 173/300\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.4523 - accuracy: 0.7817\n",
      "Epoch 174/300\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 0.4522 - accuracy: 0.7800\n",
      "Epoch 175/300\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.4519 - accuracy: 0.7833\n",
      "Epoch 176/300\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.4519 - accuracy: 0.7833\n",
      "Epoch 177/300\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 0.4519 - accuracy: 0.7817\n",
      "Epoch 178/300\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.4518 - accuracy: 0.7850\n",
      "Epoch 179/300\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.4517 - accuracy: 0.7833\n",
      "Epoch 180/300\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 0.4515 - accuracy: 0.7850\n",
      "Epoch 181/300\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.4514 - accuracy: 0.7817\n",
      "Epoch 182/300\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.4515 - accuracy: 0.7833\n",
      "Epoch 183/300\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 0.4512 - accuracy: 0.7833\n",
      "Epoch 184/300\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.4513 - accuracy: 0.7733\n",
      "Epoch 185/300\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 0.4510 - accuracy: 0.7783\n",
      "Epoch 186/300\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 0.4511 - accuracy: 0.7833\n",
      "Epoch 187/300\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.4508 - accuracy: 0.7833\n",
      "Epoch 188/300\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.4507 - accuracy: 0.7867\n",
      "Epoch 189/300\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.4509 - accuracy: 0.7867\n",
      "Epoch 190/300\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.4507 - accuracy: 0.7817\n",
      "Epoch 191/300\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.4509 - accuracy: 0.7867\n",
      "Epoch 192/300\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 0.4501 - accuracy: 0.7900\n",
      "Epoch 193/300\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 0.4516 - accuracy: 0.7850\n",
      "Epoch 194/300\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.4502 - accuracy: 0.7800\n",
      "Epoch 195/300\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 0.4505 - accuracy: 0.7850\n",
      "Epoch 196/300\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.4499 - accuracy: 0.7800\n",
      "Epoch 197/300\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 0.4503 - accuracy: 0.7833\n",
      "Epoch 198/300\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 0.4509 - accuracy: 0.7850\n",
      "Epoch 199/300\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.4496 - accuracy: 0.7800\n",
      "Epoch 200/300\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 0.4501 - accuracy: 0.7717\n",
      "Epoch 201/300\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 0.4499 - accuracy: 0.7850\n",
      "Epoch 202/300\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.4494 - accuracy: 0.7817\n",
      "Epoch 203/300\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 0.4493 - accuracy: 0.7833\n",
      "Epoch 204/300\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.4493 - accuracy: 0.7817\n",
      "Epoch 205/300\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.4493 - accuracy: 0.7867\n",
      "Epoch 206/300\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 0.4494 - accuracy: 0.7867\n",
      "Epoch 207/300\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.4500 - accuracy: 0.7867\n",
      "Epoch 208/300\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.4489 - accuracy: 0.7867\n",
      "Epoch 209/300\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.4490 - accuracy: 0.7850\n",
      "Epoch 210/300\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 0.4491 - accuracy: 0.7833\n",
      "Epoch 211/300\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.4493 - accuracy: 0.7833\n",
      "Epoch 212/300\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 0.4488 - accuracy: 0.7817\n",
      "Epoch 213/300\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 0.4487 - accuracy: 0.7800\n",
      "Epoch 214/300\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.4485 - accuracy: 0.7883\n",
      "Epoch 215/300\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 0.4484 - accuracy: 0.7867\n",
      "Epoch 216/300\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.4484 - accuracy: 0.7833\n",
      "Epoch 217/300\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 0.4483 - accuracy: 0.7867\n",
      "Epoch 218/300\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 0.4482 - accuracy: 0.7933\n",
      "Epoch 219/300\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.4483 - accuracy: 0.7950\n",
      "Epoch 220/300\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 0.4486 - accuracy: 0.7917\n",
      "Epoch 221/300\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 0.4480 - accuracy: 0.7933\n",
      "Epoch 222/300\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.4481 - accuracy: 0.7917\n",
      "Epoch 223/300\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 0.4479 - accuracy: 0.7900\n",
      "Epoch 224/300\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 0.4482 - accuracy: 0.7850\n",
      "Epoch 225/300\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.4479 - accuracy: 0.7950\n",
      "Epoch 226/300\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.4478 - accuracy: 0.7933\n",
      "Epoch 227/300\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.4483 - accuracy: 0.7900\n",
      "Epoch 228/300\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.4478 - accuracy: 0.7883\n",
      "Epoch 229/300\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.4476 - accuracy: 0.7917\n",
      "Epoch 230/300\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 0.4476 - accuracy: 0.7883\n",
      "Epoch 231/300\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.4475 - accuracy: 0.7933\n",
      "Epoch 232/300\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 0.4477 - accuracy: 0.7933\n",
      "Epoch 233/300\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 0.4477 - accuracy: 0.7950\n",
      "Epoch 234/300\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.4478 - accuracy: 0.7800\n",
      "Epoch 235/300\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 0.4473 - accuracy: 0.7900\n",
      "Epoch 236/300\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.4476 - accuracy: 0.7933\n",
      "Epoch 237/300\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.4474 - accuracy: 0.7933\n",
      "Epoch 238/300\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.4472 - accuracy: 0.7917\n",
      "Epoch 239/300\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 0.4471 - accuracy: 0.7883\n",
      "Epoch 240/300\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.4469 - accuracy: 0.7867\n",
      "Epoch 241/300\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 0.4470 - accuracy: 0.7867\n",
      "Epoch 242/300\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.4474 - accuracy: 0.7850\n",
      "Epoch 243/300\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.4471 - accuracy: 0.7883\n",
      "Epoch 244/300\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.4473 - accuracy: 0.7817\n",
      "Epoch 245/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30/30 [==============================] - 0s 4ms/step - loss: 0.4467 - accuracy: 0.7933\n",
      "Epoch 246/300\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 0.4467 - accuracy: 0.7917\n",
      "Epoch 247/300\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.4468 - accuracy: 0.7900\n",
      "Epoch 248/300\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 0.4469 - accuracy: 0.7900\n",
      "Epoch 249/300\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 0.4474 - accuracy: 0.7950\n",
      "Epoch 250/300\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.4465 - accuracy: 0.7900\n",
      "Epoch 251/300\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 0.4466 - accuracy: 0.7917\n",
      "Epoch 252/300\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 0.4466 - accuracy: 0.7917\n",
      "Epoch 253/300\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.4464 - accuracy: 0.7867\n",
      "Epoch 254/300\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 0.4466 - accuracy: 0.7833\n",
      "Epoch 255/300\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 0.4464 - accuracy: 0.7900\n",
      "Epoch 256/300\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.4463 - accuracy: 0.7933\n",
      "Epoch 257/300\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.4461 - accuracy: 0.7900\n",
      "Epoch 258/300\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 0.4468 - accuracy: 0.7833\n",
      "Epoch 259/300\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.4461 - accuracy: 0.7933\n",
      "Epoch 260/300\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 0.4460 - accuracy: 0.7917\n",
      "Epoch 261/300\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.4459 - accuracy: 0.7900\n",
      "Epoch 262/300\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.4461 - accuracy: 0.7933\n",
      "Epoch 263/300\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.4458 - accuracy: 0.7883\n",
      "Epoch 264/300\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 0.4458 - accuracy: 0.7917\n",
      "Epoch 265/300\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.4458 - accuracy: 0.7933\n",
      "Epoch 266/300\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.4460 - accuracy: 0.7917\n",
      "Epoch 267/300\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 0.4458 - accuracy: 0.7900\n",
      "Epoch 268/300\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 0.4456 - accuracy: 0.7867\n",
      "Epoch 269/300\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.4454 - accuracy: 0.7883\n",
      "Epoch 270/300\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.4468 - accuracy: 0.7783\n",
      "Epoch 271/300\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.4459 - accuracy: 0.7800\n",
      "Epoch 272/300\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.4454 - accuracy: 0.7867\n",
      "Epoch 273/300\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.4455 - accuracy: 0.7850\n",
      "Epoch 274/300\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.4454 - accuracy: 0.7933\n",
      "Epoch 275/300\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 0.4457 - accuracy: 0.7900\n",
      "Epoch 276/300\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.4454 - accuracy: 0.7917\n",
      "Epoch 277/300\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.4458 - accuracy: 0.7883\n",
      "Epoch 278/300\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 0.4453 - accuracy: 0.7900\n",
      "Epoch 279/300\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.4452 - accuracy: 0.7883\n",
      "Epoch 280/300\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.4457 - accuracy: 0.7833\n",
      "Epoch 281/300\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 0.4453 - accuracy: 0.7933\n",
      "Epoch 282/300\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.4450 - accuracy: 0.7933\n",
      "Epoch 283/300\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 0.4449 - accuracy: 0.7933\n",
      "Epoch 284/300\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 0.4451 - accuracy: 0.7883\n",
      "Epoch 285/300\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.4451 - accuracy: 0.7950\n",
      "Epoch 286/300\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 0.4450 - accuracy: 0.7833\n",
      "Epoch 287/300\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 0.4450 - accuracy: 0.7917\n",
      "Epoch 288/300\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 0.4448 - accuracy: 0.7917\n",
      "Epoch 289/300\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.4448 - accuracy: 0.7917\n",
      "Epoch 290/300\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.4450 - accuracy: 0.7867\n",
      "Epoch 291/300\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 0.4448 - accuracy: 0.7900\n",
      "Epoch 292/300\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.4447 - accuracy: 0.7917\n",
      "Epoch 293/300\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 0.4448 - accuracy: 0.7917\n",
      "Epoch 294/300\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.4446 - accuracy: 0.7883\n",
      "Epoch 295/300\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.4450 - accuracy: 0.7933\n",
      "Epoch 296/300\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 0.4445 - accuracy: 0.7933\n",
      "Epoch 297/300\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.4450 - accuracy: 0.7850\n",
      "Epoch 298/300\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.4453 - accuracy: 0.7817\n",
      "Epoch 299/300\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 0.4446 - accuracy: 0.7900\n",
      "Epoch 300/300\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 0.4444 - accuracy: 0.7917\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f17bc6dbb70>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = generatemodel(kval)\n",
    "\n",
    "model.fit(trainparamnorm, trainlabel, batch_size=20, epochs=itergd, verbose=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.14226177]\n",
      " [0.7942637 ]\n",
      " [0.4192235 ]\n",
      " [0.11769417]\n",
      " [0.28212443]\n",
      " [0.09843999]\n",
      " [0.98414254]\n",
      " [0.0889515 ]\n",
      " [0.16207123]\n",
      " [0.96188027]\n",
      " [0.19241598]\n",
      " [0.92546797]\n",
      " [0.4775582 ]\n",
      " [0.10335788]\n",
      " [0.13517427]\n",
      " [0.08925435]\n",
      " [0.62421924]\n",
      " [0.67630213]\n",
      " [0.17626053]\n",
      " [0.5144363 ]\n",
      " [0.7797104 ]\n",
      " [0.5087481 ]\n",
      " [0.98127127]\n",
      " [0.50575006]\n",
      " [0.13213292]\n",
      " [0.13194397]\n",
      " [0.5046309 ]\n",
      " [0.25778627]\n",
      " [0.3369611 ]\n",
      " [0.36234227]\n",
      " [0.29578927]\n",
      " [0.13134241]\n",
      " [0.11886641]\n",
      " [0.9273324 ]\n",
      " [0.47646543]\n",
      " [0.11068642]\n",
      " [0.4884846 ]\n",
      " [0.15037882]\n",
      " [0.9178339 ]\n",
      " [0.6046053 ]\n",
      " [0.349041  ]\n",
      " [0.12269634]\n",
      " [0.10688809]\n",
      " [0.38991976]\n",
      " [0.5047877 ]\n",
      " [0.11886641]\n",
      " [0.9892609 ]\n",
      " [0.12642816]\n",
      " [0.0796923 ]\n",
      " [0.14549336]\n",
      " [0.5211115 ]\n",
      " [0.10825711]\n",
      " [0.49718428]\n",
      " [0.16568214]\n",
      " [0.08871838]\n",
      " [0.23689023]\n",
      " [0.91242814]\n",
      " [0.12115538]\n",
      " [0.40112662]\n",
      " [0.49055365]\n",
      " [0.3229537 ]\n",
      " [0.4177095 ]\n",
      " [0.8111741 ]\n",
      " [0.51113635]\n",
      " [0.41770867]\n",
      " [0.14230046]\n",
      " [0.17574504]\n",
      " [0.97766066]\n",
      " [0.1539559 ]\n",
      " [0.09456548]\n",
      " [0.16141   ]\n",
      " [0.2997406 ]\n",
      " [0.9891556 ]\n",
      " [0.09876019]\n",
      " [0.18331873]\n",
      " [0.08801961]\n",
      " [0.09637517]\n",
      " [0.19005153]\n",
      " [0.30131853]\n",
      " [0.23979598]\n",
      " [0.5141765 ]\n",
      " [0.9786159 ]\n",
      " [0.82067835]\n",
      " [0.5056746 ]\n",
      " [0.8742302 ]\n",
      " [0.24958608]\n",
      " [0.5019778 ]\n",
      " [0.08334795]\n",
      " [0.25625336]\n",
      " [0.9353286 ]\n",
      " [0.22966972]\n",
      " [0.825465  ]\n",
      " [0.9108442 ]\n",
      " [0.50383645]\n",
      " [0.30965388]\n",
      " [0.12642056]\n",
      " [0.9533924 ]\n",
      " [0.45454764]\n",
      " [0.08736175]\n",
      " [0.9211849 ]\n",
      " [0.5073484 ]\n",
      " [0.15966311]\n",
      " [0.16859043]\n",
      " [0.87909454]\n",
      " [0.92287236]\n",
      " [0.10103688]\n",
      " [0.50060785]\n",
      " [0.1978921 ]\n",
      " [0.13213292]\n",
      " [0.4588004 ]\n",
      " [0.20440802]\n",
      " [0.9830992 ]\n",
      " [0.52928275]\n",
      " [0.10389818]]\n",
      "[0.14226177] 0.0\n",
      "[0.7942637] 1.0\n",
      "[0.4192235] 1.0\n",
      "[0.11769417] 0.0\n",
      "[0.28212443] 0.0\n",
      "[0.09843999] 0.0\n",
      "[0.98414254] 1.0\n",
      "[0.0889515] 0.0\n",
      "[0.16207123] 1.0\n",
      "[0.96188027] 1.0\n",
      "[0.19241598] 0.0\n",
      "[0.92546797] 1.0\n",
      "[0.4775582] 0.0\n",
      "[0.10335788] 0.0\n",
      "[0.13517427] 0.0\n",
      "[0.08925435] 0.0\n",
      "[0.62421924] 0.0\n",
      "[0.67630213] 1.0\n",
      "[0.17626053] 0.0\n",
      "[0.5144363] 1.0\n",
      "[0.7797104] 1.0\n",
      "[0.5087481] 1.0\n",
      "[0.98127127] 1.0\n",
      "[0.50575006] 0.0\n",
      "[0.13213292] 0.0\n",
      "[0.13194397] 0.0\n",
      "[0.5046309] 1.0\n",
      "[0.25778627] 0.0\n",
      "[0.3369611] 1.0\n",
      "[0.36234227] 0.0\n",
      "[0.29578927] 0.0\n",
      "[0.13134241] 0.0\n",
      "[0.11886641] 0.0\n",
      "[0.9273324] 1.0\n",
      "[0.47646543] 1.0\n",
      "[0.11068642] 0.0\n",
      "[0.4884846] 0.0\n",
      "[0.15037882] 0.0\n",
      "[0.9178339] 1.0\n",
      "[0.6046053] 1.0\n",
      "[0.349041] 1.0\n",
      "[0.12269634] 1.0\n",
      "[0.10688809] 0.0\n",
      "[0.38991976] 0.0\n",
      "[0.5047877] 0.0\n",
      "[0.11886641] 0.0\n",
      "[0.9892609] 1.0\n",
      "[0.12642816] 0.0\n",
      "[0.0796923] 0.0\n",
      "[0.14549336] 0.0\n",
      "[0.5211115] 0.0\n",
      "[0.10825711] 0.0\n",
      "[0.49718428] 0.0\n",
      "[0.16568214] 0.0\n",
      "[0.08871838] 0.0\n",
      "[0.23689023] 0.0\n",
      "[0.91242814] 1.0\n",
      "[0.12115538] 1.0\n",
      "[0.40112662] 0.0\n",
      "[0.49055365] 1.0\n",
      "[0.3229537] 0.0\n",
      "[0.4177095] 1.0\n",
      "[0.8111741] 1.0\n",
      "[0.51113635] 1.0\n",
      "[0.41770867] 1.0\n",
      "[0.14230046] 0.0\n",
      "[0.17574504] 0.0\n",
      "[0.97766066] 1.0\n",
      "[0.1539559] 0.0\n",
      "[0.09456548] 1.0\n",
      "[0.16141] 0.0\n",
      "[0.2997406] 0.0\n",
      "[0.9891556] 1.0\n",
      "[0.09876019] 0.0\n",
      "[0.18331873] 0.0\n",
      "[0.08801961] 0.0\n",
      "[0.09637517] 0.0\n",
      "[0.19005153] 0.0\n",
      "[0.30131853] 0.0\n",
      "[0.23979598] 0.0\n",
      "[0.5141765] 0.0\n",
      "[0.9786159] 1.0\n",
      "[0.82067835] 0.0\n",
      "[0.5056746] 1.0\n",
      "[0.8742302] 1.0\n",
      "[0.24958608] 1.0\n",
      "[0.5019778] 1.0\n",
      "[0.08334795] 0.0\n",
      "[0.25625336] 0.0\n",
      "[0.9353286] 1.0\n",
      "[0.22966972] 0.0\n",
      "[0.825465] 1.0\n",
      "[0.9108442] 1.0\n",
      "[0.50383645] 0.0\n",
      "[0.30965388] 1.0\n",
      "[0.12642056] 0.0\n",
      "[0.9533924] 1.0\n",
      "[0.45454764] 0.0\n",
      "[0.08736175] 0.0\n",
      "[0.9211849] 1.0\n",
      "[0.5073484] 1.0\n",
      "[0.15966311] 0.0\n",
      "[0.16859043] 0.0\n",
      "[0.87909454] 1.0\n",
      "[0.92287236] 1.0\n",
      "[0.10103688] 0.0\n",
      "[0.50060785] 0.0\n",
      "[0.1978921] 0.0\n",
      "[0.13213292] 0.0\n",
      "[0.4588004] 0.0\n",
      "[0.20440802] 0.0\n",
      "[0.9830992] 1.0\n",
      "[0.52928275] 1.0\n",
      "[0.10389818] 0.0\n",
      "0.8157894736842105 0.12853582\n"
     ]
    }
   ],
   "source": [
    "lifeprob = model.predict(testparamnorm)\n",
    "print(lifeprob)\n",
    "#determine biner accuracy\n",
    "binpred = np.zeros((len(lifeprob)))\n",
    "for i in range(len(lifeprob)):\n",
    "    if lifeprob[i] > 0.5:\n",
    "        binpred[i] = 1.\n",
    "score = 0\n",
    "for i in range(len(testlabel)):\n",
    "    if binpred[i] == testlabel[i]:\n",
    "        score += 1\n",
    "accbin = float(score) / float(len(testlabel))\n",
    "#determine brier score\n",
    "brierscore = 0\n",
    "for i in range(len(testlabel)):\n",
    "    brierscore += (testlabel[i] - lifeprob[i])**2.0\n",
    "brierscore = brierscore / float(len(testlabel))\n",
    "for i in range(len(testlabel)):\n",
    "    print(lifeprob[i], testlabel[i])\n",
    "print(accbin, brierscore[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
