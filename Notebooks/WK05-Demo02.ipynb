{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "from tensorboard.plugins import projector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:TFDS datasets with text encoding are deprecated and will be removed in a future version. Instead, you should use the plain text version and tokenize the text using `tensorflow_text` (See: https://www.tensorflow.org/tutorials/tensorflow_text/intro#tfdata_example)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tfds.core.DatasetInfo(\n",
      "    name='imdb_reviews',\n",
      "    version=1.0.0,\n",
      "    description='Large Movie Review Dataset.\n",
      "This is a dataset for binary sentiment classification containing substantially more data than previous benchmark datasets. We provide a set of 25,000 highly polar movie reviews for training, and 25,000 for testing. There is additional unlabeled data for use as well.',\n",
      "    homepage='http://ai.stanford.edu/~amaas/data/sentiment/',\n",
      "    features=FeaturesDict({\n",
      "        'label': ClassLabel(shape=(), dtype=tf.int64, num_classes=2),\n",
      "        'text': Text(shape=(None,), dtype=tf.int64, encoder=<SubwordTextEncoder vocab_size=8185>),\n",
      "    }),\n",
      "    total_num_examples=100000,\n",
      "    splits={\n",
      "        'test': 25000,\n",
      "        'train': 25000,\n",
      "        'unsupervised': 50000,\n",
      "    },\n",
      "    supervised_keys=('text', 'label'),\n",
      "    citation=\"\"\"@InProceedings{maas-EtAl:2011:ACL-HLT2011,\n",
      "      author    = {Maas, Andrew L.  and  Daly, Raymond E.  and  Pham, Peter T.  and  Huang, Dan  and  Ng, Andrew Y.  and  Potts, Christopher},\n",
      "      title     = {Learning Word Vectors for Sentiment Analysis},\n",
      "      booktitle = {Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies},\n",
      "      month     = {June},\n",
      "      year      = {2011},\n",
      "      address   = {Portland, Oregon, USA},\n",
      "      publisher = {Association for Computational Linguistics},\n",
      "      pages     = {142--150},\n",
      "      url       = {http://www.aclweb.org/anthology/P11-1015}\n",
      "    }\"\"\",\n",
      "    redistribution_info=,\n",
      ")\n",
      "\n"
     ]
    }
   ],
   "source": [
    "(train_data, test_data), info = tfds.load(\n",
    "    \"imdb_reviews/subwords8k\",\n",
    "    split=(tfds.Split.TRAIN, tfds.Split.TEST),\n",
    "    with_info=True,\n",
    "    as_supervised=True,\n",
    ")\n",
    "\n",
    "print(info)\n",
    "encoder = info.features[\"text\"].encoder\n",
    "\n",
    "# shuffle and pad the data.\n",
    "train_batches = train_data.shuffle(1000).padded_batch(\n",
    "    10, padded_shapes=((None,), ())\n",
    ")\n",
    "test_batches = test_data.shuffle(1000).padded_batch(\n",
    "    10, padded_shapes=((None,), ())\n",
    ")\n",
    "train_batch, train_labels = next(iter(train_batches))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2500/2500 [==============================] - 17s 7ms/step - loss: 0.5003 - accuracy: 0.7012 - val_loss: 0.3409 - val_accuracy: 0.8450\n"
     ]
    }
   ],
   "source": [
    "# Create an embedding layer\n",
    "embedding_dim = 16\n",
    "embedding = tf.keras.layers.Embedding(encoder.vocab_size, embedding_dim)\n",
    "# Train this embedding as part of a keras model\n",
    "model = tf.keras.Sequential(\n",
    "    [\n",
    "        embedding, # The embedding layer should be the first layer in a model.\n",
    "        tf.keras.layers.GlobalAveragePooling1D(),\n",
    "        tf.keras.layers.Dense(16, activation=\"relu\"),\n",
    "        tf.keras.layers.Dense(1),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Compile model\n",
    "model.compile(\n",
    "    optimizer=\"adam\",\n",
    "    loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "    metrics=[\"accuracy\"],\n",
    ")\n",
    "\n",
    "# Train model\n",
    "history = model.fit(\n",
    "    train_batches, epochs=1, validation_data=test_batches, validation_steps=20\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up a logs directory, so Tensorboard knows where to look for files\n",
    "log_dir='visualizations/'\n",
    "if not os.path.exists(log_dir):\n",
    "    os.makedirs(log_dir)\n",
    "\n",
    "# Save Labels separately on a line-by-line manner.\n",
    "with open(os.path.join(log_dir, 'metadata.tsv'), \"w\") as f:\n",
    "    for subwords in encoder.subwords:\n",
    "        f.write(\"{}\\n\".format(subwords))\n",
    "    # Fill in the rest of the labels with \"unknown\"\n",
    "    for unknown in range(1, encoder.vocab_size - len(encoder.subwords)):\n",
    "        f.write(\"unknown #{}\\n\".format(unknown))\n",
    "\n",
    "\n",
    "# Save the weights we want to analyse as a variable. Note that the first\n",
    "# value represents any unknown word, which is not in the metadata, so\n",
    "# we will remove that value.\n",
    "weights = tf.Variable(model.layers[0].get_weights()[0][1:])\n",
    "# Create a checkpoint from embedding, the filename and key are\n",
    "# name of the tensor.\n",
    "checkpoint = tf.train.Checkpoint(embedding=weights)\n",
    "checkpoint.save(os.path.join(log_dir, \"embedding.ckpt\"))\n",
    "\n",
    "# Set up config\n",
    "config = projector.ProjectorConfig()\n",
    "embedding = config.embeddings.add()\n",
    "# The name of the tensor will be suffixed by `/.ATTRIBUTES/VARIABLE_VALUE`\n",
    "embedding.tensor_name = \"embedding/.ATTRIBUTES/VARIABLE_VALUE\"\n",
    "embedding.metadata_path = 'metadata.tsv'\n",
    "projector.visualize_embeddings(log_dir, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
